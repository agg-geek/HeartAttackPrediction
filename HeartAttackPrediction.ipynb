{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Attack Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is created for the **Biotech Final Year Project** of **MNNIT Allahabad, Dept of Biotechnology**.   \n",
    "The notebook contains code to predict risk of heart attack using various Machine Learning techniques based on health and heart-based parameters.\n",
    "\n",
    "This notebook and all other relevant files are available on [Github](https://github.com/agg-geek/HeartAttackPrediction).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Supervisor:\n",
    "Dr. Ashutosh Mani,  \n",
    "Associate Professor, Department of Biotechnology\n",
    "\n",
    "### Project team members:\n",
    "- Abhinav Aggarwal, 20200003\n",
    "- Ratna Rathaur, 20200041\n",
    "- Shivam Pandey, 20200049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.style.use('ggplot')\n",
    "# matplotlib.style.use('fivethirtyeight')\n",
    "# matplotlib.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age', 'sex', 'cp', 'bp', 'chol', 'fbs', 'ecg', 'maxhr', 'angina', 'oldpeak', 'stslope', 'vessel', 'thal', 'attack']\n",
    "heart = pd.read_csv('dataset/cleveland.data', names=column_names, sep=',', na_values='?')\n",
    "heart.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `age`: Age of the patient (years)\n",
    "- `sex`: Sex of the patient (1: Male or 0: Female)\n",
    "- `cp`:  Chest pain type (0: Typical Angina, 1: Atypical Angina, 2: Non-Anginal Pain, 3: Asymptomatic)\n",
    "- `bp`:  Resting blood pressure (mm Hg)\n",
    "- `chol`:  Cholesterol level (mg/dL)\n",
    "- `fbs`: Fasting blood sugar (1: if fbs > 120 mg/dl, 0: otherwise)\n",
    "- `ecg`: Resting ECG results\n",
    "    - 0: Normal\n",
    "    - 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    - 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "- `maxhr`: Maximum heart rate achieved (bpm)  \n",
    "- `angina`: Exercise Induced Angina (1: Yes, 0: No)\n",
    "- `oldpeak`: ST depression induced by exercise relative to rest\n",
    "- `stslope`: Slope of the peak exercise ST segment (0: upsloping, 1: flat, 2: downsloping)\n",
    "- `vessel`: Number of major vessels colored by flourosopy (0 - 4)\n",
    "- `thal`: Thalassemia blood disorder (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "- `attack`: Target variable (0 = no heart attack, 1 - 4: heart attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- There are 303 instances.\n",
    "- There are 13 features and 1 target variable.\n",
    "- All features have datatype `float64`. Many of these features can be converted to `int64` to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "There are 4 missing values in `vessel` and 2 missing values in `thal`.  \n",
    "To handle these missing values, we will need to either remove the instances containing the missing values or fill them.  \n",
    "We do not have any data to fill the missing values with. We could either fill them with the mean value of their corresponding columns or just remove them.  \n",
    "Since only 6 instances will be removed if we remove the missing values, we will simply remove the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**  \n",
    "There are no duplicated rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart['attack']\n",
    "heart['attack'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "As mentioned in the dataset description, the target column `attack` is a categorical column with 0 denoting no heart attack and other values denoting heart attack.  \n",
    "We will transform the column such that 0 indicates no heart attack and 1 indicates heart attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart['attack'] = heart['attack'].apply(lambda x: 0 if x == 0 else 1)\n",
    "# heart['attack']\n",
    "heart['attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_balance(df, target_column, risk_value, not_risk_value):\n",
    "    risk = len(df[df[target_column] == risk_value])\n",
    "    no_risk = len(df[df[target_column] == not_risk_value])\n",
    "    total = risk + no_risk\n",
    "    # print(risk, no_risk, total)\n",
    "    print(f\"Percentage Risk: {risk / total * 100}%\")\n",
    "    print(f\"Percentage Not Risk: {no_risk / total * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "numerical_features = []\n",
    "\n",
    "for col in list(heart.columns)[:-1]:\n",
    "    if heart[col].nunique() > 5:\n",
    "        numerical_features.append(col)\n",
    "    else:\n",
    "        categorical_features.append(col)\n",
    "\n",
    "print('Categorical Features :', *categorical_features)\n",
    "print('Numerical Features :', *numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib inline\n",
    "# heart.hist(bins=15, figsize=(16,10)) #figsize = (width, height)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate analysis on categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(categorical_features, 1):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.title(f\"Distribution of {col} Data\")\n",
    "    sns.histplot(heart[col])\n",
    "    plt.tight_layout()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart[categorical_features].skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- The frequency of feature values is not uniform. This maybe because some types appear more frequently than others or it maybe attributed to poor data collection techniques.\n",
    "- Distributions are not normally distributed (i.e. Gaussian). This will limit model performance for models which assume data to be normally distributed.\n",
    "<!-- Standardization using `StandardScaler` shouldn't be used to scale the data.  Normalization should be performed so something like `MinMaxScaler` can be used instead. -->\n",
    "<!-- - Scales for the features are different, will require feature scaling.  -->\n",
    "<!-- - Several numeric features are actually categorical. -->\n",
    "<!-- - **Categorical Features:** `sex`, `cp`, `fbs`, `recg`, `angina`, `stslope`, `vessel`, `thal`, and `attack`.   -->\n",
    "<!-- - **Continuous Features:** `age`, `bp`, `chol`, `maxhr`, `oldpeak`. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate analysis on numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(numerical_features, 1):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.title(f\"Distribution of {col} Data\")\n",
    "    # sns.kdeplot(heart[col], linewidth=1)\n",
    "    sns.histplot(heart[col], kde=True, line_kws={'lw':1.5}, stat='density')\n",
    "    # sns.histplot(heart[col], kde=True, line_kws={'lw':1.5}, stat='density', kde_kws=dict(cut=3))\n",
    "    # sns.distplot(heart[col], kde_kws={'bw':1})\n",
    "    plt.tight_layout()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart[numerical_features].skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Scales for the features are different, will require feature scaling. \n",
    "- Standardization using `StandardScaler` shouldn't be used to scale the data.  Normalization should be performed so something like `MinMaxScaler` can be used instead.\n",
    "- Distributions are not normally distributed (i.e. Gaussian). This will limit model performance for models which assume data to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate analysis on target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_balance(heart, 'attack', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- The frequency of the target values are not very different.  This is a very balanced dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
